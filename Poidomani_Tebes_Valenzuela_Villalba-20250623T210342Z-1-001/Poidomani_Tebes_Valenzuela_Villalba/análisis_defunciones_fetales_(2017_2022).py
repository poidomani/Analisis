# -*- coding: utf-8 -*-
"""An√°lisis_Defunciones Fetales (2017-2022).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fp6FJ91G8f_yL9_PEkH5CK9y0-rr582h

# Introducci√≥n al TP General

En este TP de Introducci√≥n, tiene el proposito de explorar y analizar la base de datos: Defunciones Fetales (2017-2022) extraida de la p√°gina de Datos Abiertos PBA en su secci√≥n de Salud.

Link: https://catalogo.datos.gba.gob.ar/dataset/defunciones-fetales

Autoras:

* *Poidomani Mabel*
* *Tebes Stella Maris*
* *Valenzuela Sonia Daniela*
* *Villalba Camila*

# Primero cargamos los paquetes y los datos

Instalaci√≥n de Paquetes, luego los importamos.
"""

#Comentados para que no se ejecuten

# !pip install pandas
# !pip install matplotlib
!pip install seaborn
!pip install numpy
!pip install pandas==1.5.3     # Una versi√≥n espec√≠fica de Pandas
!pip install ydata-profiling   # Para generar un reporte completo

# Commented out IPython magic to ensure Python compatibility.
# =============================================
# CONFIGURACI√ìN INICIAL PARA GOOGLE COLAB
# =============================================

# Magic command de Jupyter/IPython: Para mostrar gr√°ficos inline directamente en el notebook
# %matplotlib inline

# =============================================
# IMPORTACI√ìN DE LIBRER√çAS B√ÅSICAS
# =============================================

import os  # M√≥dulo OS: Para interactuar con el sistema operativo (manejo de archivos/directorios)
import numpy as np  # Para operaciones num√©ricas y √°lgebra lineal
import pandas as pd  # Para manejo y an√°lisis de datos en DataFrames

# =============================================
# IMPORTACI√ìN DE LIBRER√çAS DE VISUALIZACI√ìN
# =============================================

import matplotlib.pyplot as plt  # Para creaci√≥n de gr√°ficos b√°sicos
import seaborn as sns  # Para visualizaciones estad√≠sticas avanzadas - Se integra con Matplotlib para mejorar los gr√°ficos.

# =============================================
# CONFIGURACI√ìN DE ESTILOS Y PAR√ÅMETROS
# =============================================

# Configuraci√≥n espec√≠fica de Seaborn:
# - "whitegrid": fondo con cuadr√≠cula
# - color_codes: permite usar c√≥digos de color simples ('b', 'g', 'r', etc.)
sns.set(style="whitegrid", color_codes=True)

"""Montamos el Drive:"""

from google.colab import drive
drive.mount('/content/drive')

"""Aqu√≠ cargaremos la base de datos de "Defunciones Fetales (2017 - 2022)" para hacer una primera visualizaci√≥n de c√≥mo se ven los datos originales del DataFrame, previo a realizar cualquier cambio que se considere conveniente para su posterior analisis.

C√≥digo para visualizaci√≥n inicial (antes de hacer cualquier modificaci√≥n):
"""

# PASO 1 - CARGA ORIGINAL (sin modificaciones)
print("=== DATOS ORIGINALES ===")
df_original = pd.read_csv("/content/drive/MyDrive/MD-TP General/defunciones-fetales-2017_2022.csv")

# 1. Mostrar estructura b√°sica
print("\nüîç Estructura Inicial:")
print(f"‚Ä¢ Filas: {len(df_original)}")
print(f"‚Ä¢ Nombres reales de las Columnas: {df_original.columns.tolist()}")
print(f"‚Ä¢ Tipo de datos:\n{df_original.dtypes}")
print()

# 2. Mostrar muestra de datos (configuraci√≥n temporal)
with pd.option_context('display.max_rows', 10, 'display.max_columns', None):
    print("\nüìã Vista previa (10 primeras filas):")
    display(df_original.head(10))

# 3. Guardar metadatos para comparaci√≥n posterior
forma_original = df_original.shape
columnas_originales = df_original.columns.tolist()
muestra_indice_original = df_original.iloc[:3].to_dict('records')

"""Una vez que observamos los datos que tenemos en el DataFrame, queremos hacer unas modificaciones en la carga de los datos para optimizar la visualizaci√≥n de los mismos.

Se proceder√° a cambiar los nombres de las columnas para simplificarlas y lograr una mejor comprensi√≥n; adem√°s se establecer√° la variable a√±o como √≠ndice del tipo period[Y-DEC], para posteriores analisis temporales.
"""

# Cargar el CSV y renombrar las columnas:
df = pd.read_csv(
    '/content/drive/MyDrive/MD-TP General/defunciones-fetales-2017_2022.csv',
    dtype={'anio': str} # Leer 'anio' como texto para evitar problemas
).rename(columns={
    'anio': 'A√±o',
    'residencia_muncipio_id\xa0': 'ID Municipio',
    'residencia_muncipio_nombre': 'Municipio',
    'cantidad\xa0': 'Cantidad Defunciones'
})

# Convertir a √≠ndice de PERIODO ANUAL (solo a√±o, sin mes/d√≠a ficticios)
df['A√±o'] = pd.to_datetime(df['A√±o'], format='%Y').dt.to_period('Y')  # 2017, 2018, ...
df = df.set_index('A√±o')

# VERIFICACIONES:

# Mostrar el DataFrame (√≠ndice solo con a√±o):
print("\nDataFrame con √≠ndice de A√ëO PURO (Periodo):")
display(df.head(5))

# Mostrar el tipo de √≠ndice:
print("\nTipo del √≠ndice:", df.index.dtype)  # period[Y-DEC] (a√±o puro)

# Verificaci√≥n r√°pida para confirmar que el √≠ndice (ahora compuesto por a√±os) reconoce correctamente
#los valores como rangos temporales, a pesar de no usar datetime:
print("\n¬øPuedo filtrar por rango?", '2018' in df.index)  # Tiene que decir True ‚úÖ

# Inspeccionar los nombres modificados de las columnas:
print("Nombres de Columnas:", df.columns.tolist())

"""# Observaremos a continuaci√≥n qu√© datos tenemos."""

df

"""Verificamos el n√∫mero de filas y columnas del DataFrame:"""

print(df.shape)

"""Verificamos los √∫ltimos registros:"""

df.tail(10)

"""Obtener informaci√≥n sobre las columnas del DataFrame:"""

print(df.info())

"""Estad√≠sticas descriptivas de la columna num√©rica "Cantidad Defunciones":"""

print(df['Cantidad Defunciones'].describe())

"""# Limpieza de Datos

El proceso de limpieza de datos del DataFrame, tanto en este Google Colab como en cualquier entorno de an√°lisis de datos que se realice, resulta fundamental ya que nos permite preparar los datos y asegurar que sean consistentes, completos y correctos antes de realizar an√°lisis, modelado o visualizaciones.

Procedemos a verificar si hay "Valores Nulos o Faltantes" en el DataFrame; como ser: Celdas vac√≠as (NaN, None) o marcadores incorrectos (Ej: "N/A", "Desconocido").
"""

df.isnull().sum()

"""Ya que en nuestro DataFrame no tenemos valores faltantes o nulos; ahora verificaremos si hay "Datos duplicados", es decir, filas id√©nticas repetidas."""

df.duplicated().sum()

"""Aparentemente tenemos 228 "Datos Duplicados", tenemos que explorar bien si realmente son datos redundantes o es un error.

Para ello procederemos a hacer otros analisis de duplicados m√°s exhaustivos.
"""

# AN√ÅLISIS DE DUPLICADOS
with pd.option_context('display.max_rows', None):  # Configuraci√≥n temporal

    # 1. Definir columnas clave
    columnas_clave = ['ID Municipio', 'Municipio', 'Cantidad Defunciones']

    # 2. Verificar columnas
    if not all(col in df.columns for col in columnas_clave):
        print("Error: Algunas columnas no existen")
        print("Columnas disponibles:", df.columns.tolist())
    else:
        # 3. Encontrar duplicados
        duplicados = df[df.duplicated(subset=columnas_clave, keep=False)]

        # 4. Mostrar resultados
        print(f"\nüîç Registros duplicados (basados en {columnas_clave}): {len(duplicados)}")
        print(f"(Coincide con {df.duplicated(subset=columnas_clave).sum()} duplicados reportados)")

        if len(duplicados) > 0:
            print("\nEjemplos:")
            display(duplicados.sort_values(by=columnas_clave).head(10))

def analisis_duplicados_seguro(df_original):
    """Funci√≥n encapsulada que no modifica el DataFrame original"""
    # Crear copia local para trabajar
    df = df_original.copy()

    # 1. Verificar estructura b√°sica
    print("üìä Estructura del DataFrame:")
    print(f"Total de registros: {len(df)}")
    print(f"Columnas disponibles: {df.columns.tolist()}\n")

    # 2. A√±adir columna temporal de a√±o
    df['A√±o_temp'] = df.index.year

    # 3. An√°lisis de valores √∫nicos
    print("üîç An√°lisis de valores √∫nicos:")
    print(f"A√±os registrados: {df['A√±o_temp'].nunique()} a√±os ‚Üí {sorted(df['A√±o_temp'].unique())}")
    print(f"Total municipios: {df['Municipio'].nunique()}")
    print(f"Total IDs Municipio: {df['ID Municipio'].nunique()}\n")

    # 4. Verificar consistencia entre ID Municipio y Nombre
    if df.groupby('ID Municipio')['Municipio'].nunique().max() == 1:
        print("‚úÖ Consistencia: Cada ID Municipio tiene un √∫nico nombre")
    else:
        print("‚ö†Ô∏è Inconsistencias: Hay IDs Municipio con diferentes nombres")

    # 5. Buscar duplicados (usando columna temporal)
    print("\nüîé B√∫squeda de duplicados reales (mismo a√±o y mismo municipio):")
    duplicados = df[df.duplicated(subset=['A√±o_temp', 'Municipio'], keep=False)]

    # Mostrar resultados con configuraci√≥n temporal
    with pd.option_context('display.max_rows', 10):
        if not duplicados.empty:
            print(f"Se encontraron {len(duplicados)} registros duplicados")
            print("\nEjemplos de duplicados (primeros 5):")
            display(duplicados[['ID Municipio', 'Municipio', 'Cantidad Defunciones', 'A√±o_temp']]
                   .sort_values(['A√±o_temp', 'Municipio']).head())

            # Verificar inconsistencias
            grupos = duplicados.groupby(['A√±o_temp', 'Municipio'])['Cantidad Defunciones']
            if grupos.nunique().max() > 1:
                print("\n‚ö†Ô∏è Algunos duplicados tienen cantidades diferentes")
                display(grupos.apply(list).loc[grupos.nunique() > 1])
        else:
            print("‚úÖ No hay duplicados reales")

    # 6. An√°lisis de Cantidad Defunciones (sin modificar)
    print("\nüìà Estad√≠sticas de 'Cantidad Defunciones':")
    with pd.option_context('display.max_rows', 8):
        display(df_original['Cantidad Defunciones'].describe().to_frame())

# Ejecutar an√°lisis seguro
analisis_duplicados_seguro(df)

"""Por lo visto no hay valores duplicados reales. Lo que pudo pasar es que se repetian lo datos en la variable "Cantidad Defunciones" pero era en distintos "Municipios"; asi tambi√©n se repiten los "Municipios" pero es en distintos "A√±os"; por lo cual los datos duplicados que se ve√≠an al principio no son relevantes para tomarlos en cuenta o para ser eliminados.

Ahora vamos a verificar si hay "Inconsistencias en categor√≠as/texto", es decir: Errores de formato, may√∫sculas o palabras similares con variaciones.

Ejemplo: "Adolfo Alsina" vs "adolfo alsina" (mismo municipio, diferente formato).
"""

print(df['Municipio'].unique())

# AN√ÅLISIS DE INCONSISTENCIAS EN MUNICIPIOS (SOLO LECTURA)
# --------------------------------------------------------

# 1. Crear una COPIA del DataFrame para an√°lisis
df_analisis = df.copy()

# 2. An√°lisis de valores √∫nicos (sin modificar datos originales)
print("üîç An√°lisis SIN MODIFICAR los datos originales:")
valores_unicos = df_analisis['Municipio'].unique()
print(f"\nValores √∫nicos en 'Municipio': {len(valores_unicos)}")
print("Ejemplos:", valores_unicos[:5])  # Muestra solo 5 valores

# 3. Detecci√≥n de problemas (solo visual)
problemas = {
    'Espacios extras': any("  " in x or x.startswith(" ") or x.endswith(" ") for x in valores_unicos),
    'May√∫sculas inconsistentes': len(set(x.lower() for x in valores_unicos)) < len(valores_unicos),
    'Nombres repetidos difieren': len(set(x.strip().title() for x in valores_unicos)) < len(valores_unicos)
}

print("\nüö® Problemas detectados (solo para diagn√≥stico):")
for tipo, existe in problemas.items():
    print(f"‚Ä¢ {tipo}: {'‚úÖ S√≠' if existe else '‚ùå No'}")

# 4. Ejemplos de problemas (sin alterar datos)
if problemas['May√∫sculas inconsistentes']:
    print("\nüìå Ejemplo de may√∫sculas inconsistentes:")
    ejemplo = next(x for x in valores_unicos if any(x.lower() == y.lower() and x != y for y in valores_unicos))
    print(f"Ejemplo encontrado: '{ejemplo}' vs '{next(y for y in valores_unicos if y.lower() == ejemplo.lower() and y != ejemplo)}'")

# 5. Estad√≠sticas (sin cambios reales)
print("\nüìä Datos originales preservados:")
print(f"‚Ä¢ Total municipios original: {len(valores_unicos)}")
print(f"‚Ä¢ Total si se normalizaran: {len(set(x.strip().title() for x in valores_unicos))}")
print("\nüí° Nota: Este an√°lisis NO modific√≥ el DataFrame original.")

"""Este es otro analisis para detectar alg√∫n otro tipo de inconsistencia que pueda tener la base de datos."""

# AN√ÅLISIS COMPLETO SIN MODIFICAR EL DATAFRAME
# --------------------------------------------

def analizar_datos(df_original):
    """Funci√≥n que analiza sin modificar el DataFrame original"""
    print("üîç INICIO DE AN√ÅLISIS (sin modificar datos) üîç")

    # 1. An√°lisis de tipos de datos
    print("\n1. üìê TIPOS DE DATOS:")
    print(df_original.dtypes)

    # Sugerencias de tipos (solo visual)
    sugerencias = {
        'ID Municipio': 'int64',
        'Cantidad Defunciones': 'int64'
    }
    print("\nüí° Sugerencias de tipos (basado en nombres de columnas):")
    for col, tipo in sugerencias.items():
        if col in df_original.columns:
            print(f"- {col}: {df_original[col].dtype} ‚Üí podr√≠a ser {tipo}")

    # 2. Rangos o valores inv√°lidos
    print("\n2. üî¢ RANGOS DE VALORES:")
    if 'A√±o' in df_original.columns:
        print(f"- A√±o: {df_original['A√±o'].min()} a {df_original['A√±o'].max()}")
    if 'Cantidad Defunciones' in df_original.columns:
        print(f"- Cantidad Defunciones: {df_original['Cantidad Defunciones'].min()} a {df_original['Cantidad Defunciones'].max()}")
        if (df_original['Cantidad Defunciones'] < 0).any():
            print("  ‚ö†Ô∏è ¬°Valores negativos encontrados!")

    # 3. Inconsistencias temporales
    print("\n3. üìÖ INCONSISTENCIAS TEMPORALES:")
    if 'A√±o' in df_original.columns:
        a√±os_unicos = sorted(df_original['A√±o'].unique())
        print(f"- A√±os √∫nicos: {a√±os_unicos}")

        # Verificar a√±os fuera de rango esperado
        a√±o_actual = pd.Timestamp.now().year
        a√±os_raros = [a for a in a√±os_unicos if a > a√±o_actual or a < 2000]  # Ajusta el rango seg√∫n tu contexto
        if a√±os_raros:
            print(f"  ‚ö†Ô∏è A√±os sospechosos: {a√±os_raros}")

    print("\n‚úÖ An√°lisis completado (el DataFrame NO fue modificado)")

# Ejecutar an√°lisis
analizar_datos(df)

"""Verificamos la existencia de Outliers (valores at√≠picos).
Qu√© son: Valores num√©ricos extremadamente altos/bajos que distorsionan el an√°lisis.

Ejemplo: En "Cantidad Defunciones", un valor de 500 cuando el promedio es 20.
"""

sns.boxplot(data=df, x='Cantidad Defunciones')

# AN√ÅLISIS DE VALORES EXTREMOS (NO MODIFICA DATOS)
# ------------------------------------------------

import matplotlib.pyplot as plt

def analizar_valores_extremos(df_original, columna='Cantidad Defunciones'):
    """Genera an√°lisis visual sin modificar los datos"""
    if columna not in df_original.columns:
        print(f"‚ö†Ô∏è La columna '{columna}' no existe")
        return

    print(f"\nüìä AN√ÅLISIS DE VALORES EXTREMOS PARA '{columna}':")

    # 1. Estad√≠sticas b√°sicas
    stats = df_original[columna].describe()
    print("Estad√≠sticas descriptivas:")
    print(stats)

    # 2. Detecci√≥n de outliers (solo c√°lculo)
    Q1 = stats['25%']
    Q3 = stats['75%']
    IQR = Q3 - Q1
    umbral_superior = Q3 + 1.5*IQR
    outliers = df_original[df_original[columna] > umbral_superior]

    print(f"\nüîç Valores extremos (superiores a {umbral_superior:.2f}):")
    print(f"- Cantidad de outliers: {len(outliers)}")
    print("- Ejemplos:")
    display(outliers.head(3))

    # 3. Boxplot (visualizaci√≥n segura)
    plt.figure(figsize=(8, 4))
    df_original[columna].plot(kind='box', vert=False)
    plt.title(f'Distribuci√≥n de {columna}\n(Los c√≠rculos son valores extremos)')
    plt.xlabel('Valor')
    plt.grid(True)
    plt.show()

    # 4. Sugerencias (solo visual)
    print("\nüí° Recomendaciones:")
    print("- Valores extremos pueden ser casos especiales que merecen investigaci√≥n")
    print("- Considerar si los outliers son errores o datos v√°lidos")

# Ejecutar an√°lisis (no modifica df)
analizar_valores_extremos(df)

df

"""# Analisis de Estad√≠stica Descriptiva con Gr√°ficos incluidos

Estad√≠sticas Descriptivas de la variable "Cantidad Defunciones":
"""

print(df['Cantidad Defunciones'].describe())

"""Los datos revelan una distribuci√≥n altamente asim√©trica con una marcada desigualdad en lo que respecta a las defunciones fetales entre municipios. La media (11.83) es significativamente mayor que la mediana (2), indicando que la mayor√≠a de las localidades registran pocos eventos (50% con ‚â§2 anuales), mientras que unos pocos municipios presentan cifras excepcionalmente altas, distorsionando el promedio. Esto se confirma con la alta desviaci√≥n est√°ndar (27.13), que refleja una amplia dispersi√≥n en los datos.

El an√°lisis por cuartiles muestra que el 25% de los municipios registr√≥ 1 o menos defunciones anuales, el 75% de los municipios acumula ‚â§9 casos anuales, pero el valor m√°ximo (361) en un solo municipio/ a√±o destaca como un outlier extremo, posiblemente asociado a factores como densidad poblacional, desigualdades en salud, como ser problemas espec√≠ficos de salud p√∫blica en determinadas regiones o as√≠ tambi√©n problemas de registro.


Inferencias clave:

* La mayor√≠a de los municipios tienen baja incidencia, pero unos pocos concentran cifras alarmantes.
* Los outliers reflejan realidades estructurales (ej. acceso limitado a salud) o eventos puntuales.
* Se requiere normalizar los datos (ej. defunciones por cada 1,000 nacimientos) para identificar riesgos reales.

Tras los promedios obtenidos se puede concluir que, existen disparidades que demandan intervenciones focalizadas en grupos vulnerables.


"""

# 1. FILTRAR REGISTROS IGNORADOS (2 m√©todos equivalentes)
ignorados = df[df['Municipio'] == 'Ignorado']  # Opci√≥n 1: por nombre
ignorados = df[df['ID Municipio'] == 6999]      # Opci√≥n 2: por ID (m√°s seguro)

# 2. CALCULAR TOTALES
total_ignorados = ignorados['Cantidad Defunciones'].sum()
total_general = df['Cantidad Defunciones'].sum()

# 3. PORCENTAJE (con redondeo a 1 decimal)
porcentaje_ignorados = round((total_ignorados / total_general) * 100, 1)

print(f"Defunciones ignoradas: {total_ignorados} de {total_general} ({porcentaje_ignorados}%)")

"""Podemos observar que un 10.7 % del total de las defunciones fetales registradas, no registran el nombre aut√©ntico de la localidad o municipio, est√°n registrados bajo el nombre de Ignorado, con el ID Municipio 6999.

La cantidad exacta consta de 937 defunciones en una base de datos que contempla un total de 8764 defunciones fetales.

De esto inferimos que no se trataria de un √∫nico Municipio en particular, sino que podr√≠an llegar a ser distintos Municipios ubicados tal vez en zonas de dif√≠cil acceso para hacer el relevamiento de datos completamente espec√≠ficado por zona geogr√°fica.

Aparte de "Ignorado", el municipio de la Matanza es el que registra un mayor porcentaje de defunciones fetales, un 10.1% (884 eventos). Observemos un poco su evoluci√≥n anual y la comparaci√≥n con otros municipios.

Hay un claro descenso en la cantidad de defunciones a lo largo de los a√±os 2017-2022, que puede deberse a diferentes factores como ser: Mejoras en atenci√≥n prenatal, Pol√≠ticas p√∫blicas focalizadas, Disminuci√≥n de embarazos de alto riesgo, entre otros.
"""

# =============================================
# AN√ÅLISIS DE DEFUNCIONES FETALES EN LA MATANZA
# =============================================

# Filtrar registros de La Matanza (2 m√©todos equivalentes)
# --------------------------------------------------------

# M√©todo 1: Por nombre exacto del municipio
la_matanza_nombre = df[df['Municipio'] == 'La Matanza']

# M√©todo 2: Por ID de municipio (m√°s robusto para evitar errores de escritura)
# Primero identificamos el ID correspondiente a La Matanza
id_matanza = df.loc[df['Municipio'] == 'La Matanza', 'ID Municipio'].unique()[0]
la_matanza_id = df[df['ID Municipio'] == id_matanza]

# Verificaci√≥n de coincidencia entre ambos m√©todos
assert la_matanza_nombre.shape[0] == la_matanza_id.shape[0], "Los m√©todos de filtrado no coinciden"

# Usamos el dataframe filtrado por ID (m√°s seguro)
la_matanza = la_matanza_id.copy()

# C√°lculo de estad√≠sticas
# -----------------------

# 1. Total de defunciones en La Matanza
total_matanza = la_matanza['Cantidad Defunciones'].sum()

# 2. Total general de defunciones
total_general = df['Cantidad Defunciones'].sum()

# 3. Porcentaje que representa La Matanza (redondeado a 1 decimal)
porcentaje_matanza = round((total_matanza / total_general) * 100, 1)

# Resultados principales
# ---------------------

print(f"""
AN√ÅLISIS DE DEFUNCIONES FETALES - LA MATANZA (2017-2022)
=======================================================

Defunciones totales en La Matanza: {total_matanza:,}
Defunciones totales en Provincia: {total_general:,}
Porcentaje que representa: {porcentaje_matanza}%

ID del municipio: {id_matanza}
""")

# Evoluci√≥n anual detallada
# -------------------------

print("\nEVOLUCI√ìN ANUAL:")
evolucion_anual = la_matanza.groupby(la_matanza.index.year)['Cantidad Defunciones'].sum()
print(evolucion_anual.to_string())

# Comparaci√≥n con otros municipios
# -------------------------------

print("\nCOMPARACI√ìN CON OTROS MUNICIPIOS:")
top_municipios = df.groupby('Municipio')['Cantidad Defunciones'].sum().nlargest(5)
print(top_municipios.to_string())

# Visualizaci√≥n r√°pida (opcional)
# ------------------------------

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
evolucion_anual.plot(kind='bar', color='#e6550d')
plt.title('Defunciones Fetales en La Matanza por A√±o')
plt.xlabel('A√±o')
plt.ylabel('Cantidad de Defunciones')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""A continuaci√≥n realizaremos un an√°lisis completo del DataFrame de Defunciones Fetales; con la intenci√≥n de detectar cu√°les son los municipios que registran una mayor cantidad de eventos."""

# ========================================================================
# AN√ÅLISIS COMPLETO DE DEFUNCIONES FETALES POR MUNICIPIO (2017-2022) - VERSI√ìN COMPLETA
# ========================================================================

#import pandas as pd
#import matplotlib.pyplot as plt
#import seaborn as sns
#from google.colab import drive  # Solo para Google Colab

# Configuraci√≥n de estilo para gr√°ficos
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 12

# 1. AN√ÅLISIS DE TOP 10 MUNICIPIOS CON MAYOR MORTALIDAD FETAL
# -----------------------------------------------------------

# Calcular totales por municipio
df_municipios = df.groupby(['Municipio', 'ID Municipio'])['Cantidad Defunciones'].sum().reset_index()
df_municipios = df_municipios.sort_values('Cantidad Defunciones', ascending=False)

# Obtener top 10 municipios
top_10 = df_municipios.head(10).copy()
total_provincia = df['Cantidad Defunciones'].sum()

# Calcular porcentajes
top_10['Porcentaje'] = round((top_10['Cantidad Defunciones'] / total_provincia) * 100, 2)
top_10['Porcentaje Acumulado'] = top_10['Porcentaje'].cumsum()

# Calcular datos para "Otros municipios"
otros_municipios = df_municipios[~df_municipios['Municipio'].isin(top_10['Municipio'])]
total_otros = otros_municipios['Cantidad Defunciones'].sum()
porcentaje_otros = round((total_otros / total_provincia) * 100, 2)
min_otros = otros_municipios['Cantidad Defunciones'].min()
max_otros = otros_municipios['Cantidad Defunciones'].max()
cant_otros = len(otros_municipios)

# Mostrar tabla resumen mejorada
print("="*90)
print("TOP 10 MUNICIPIOS CON MAYOR CANTIDAD DE DEFUNCIONES FETALES (2017-2022)")
print("="*90)
print(f"Total de defunciones en Provincia Buenos Aires: {total_provincia:,}\n")
print(top_10[['Municipio', 'ID Municipio', 'Cantidad Defunciones', 'Porcentaje', 'Porcentaje Acumulado']].to_string(index=False))
print(f"\nOtros {cant_otros} municipios: {total_otros:,} defunciones ({porcentaje_otros}%)")
print(f"Rango en otros municipios: desde {min_otros} hasta {max_otros} defunciones")

# 2. AN√ÅLISIS DETALLADO POR MUNICIPIO (EVOLUCI√ìN ANUAL)
# -----------------------------------------------------

# Obtener datos anuales para los top 10 municipios
top_10_names = top_10['Municipio'].tolist()
df_top_10 = df[df['Municipio'].isin(top_10_names)]

# Pivotear datos para mejor visualizaci√≥n
pivot_anual = df_top_10.pivot_table(
    index='A√±o',
    columns='Municipio',
    values='Cantidad Defunciones',
    aggfunc='sum'
).fillna(0)

# Reordenar columnas seg√∫n ranking
pivot_anual = pivot_anual[top_10_names]

print("\n" + "="*90)
print("EVOLUCI√ìN ANUAL DE DEFUNCIONES EN TOP 10 MUNICIPIOS")
print("="*90)
print(pivot_anual.to_string())

# 3. AN√ÅLISIS COMPARATIVO: LA MATANZA VS OTROS MUNICIPIOS
# -------------------------------------------------------

# Datos espec√≠ficos para La Matanza
la_matanza = df[df['Municipio'] == 'La Matanza']
total_matanza = la_matanza['Cantidad Defunciones'].sum()
porc_matanza = round((total_matanza / total_provincia) * 100, 2)

# Comparaci√≥n con otros grandes municipios
comparacion = top_10[top_10['Municipio'] != 'La Matanza'].head(3)
otros_municipios_comparacion = comparacion[['Municipio', 'Cantidad Defunciones', 'Porcentaje']]

print("\n" + "="*90)
print("COMPARACI√ìN: LA MATANZA VS OTROS MUNICIPIOS PRINCIPALES")
print("="*90)
print(f"La Matanza: {total_matanza:,} defunciones ({porc_matanza}% del total)\n")
print("Otros municipios relevantes:")
print(otros_municipios_comparacion.to_string(index=False))

# 4. VISUALIZACIONES PROFESIONALES COMPLETAS
# ------------------------------------------

# Gr√°fico 1: Gr√°fico circular mejorado con categor√≠a "Otros municipios"
plt.figure(figsize=(14, 10))

# Preparar datos para el pie chart
labels = top_10['Municipio'].tolist() + [f"Otros {cant_otros} municipios"]
sizes = top_10['Cantidad Defunciones'].tolist() + [total_otros]
colors = plt.cm.tab20c.colors[:len(labels)]

# Crear el gr√°fico con porcentajes reales
patches, texts, autotexts = plt.pie(
    sizes,
    labels=labels,
    colors=colors,
    autopct='%1.1f%%',
    startangle=140,
    pctdistance=0.85,
    labeldistance=1.05,
    wedgeprops={'linewidth': 1, 'edgecolor': 'white'},
    textprops={'fontsize': 10}
)

# Ajustar posici√≥n de los porcentajes
plt.setp(autotexts, size=10, weight="bold", color="white")

# A√±adir t√≠tulo y leyenda descriptiva
plt.title('Distribuci√≥n de Defunciones Fetales por Municipio\n(2017-2022)', fontsize=16, pad=20)
plt.legend(
    title=f"Detalle Otros Municipios:\n{cant_otros} municipios ({porcentaje_otros}%)\nRango: {min_otros}-{max_otros} defunciones",
    loc="center left",
    bbox_to_anchor=(1, 0.5),
    fontsize=10
)

# A√±adir c√≠rculo central para donut chart
centre_circle = plt.Circle((0,0), 0.70, fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.tight_layout()
plt.show()

# Gr√°fico 2: Comparaci√≥n La Matanza vs otros municipios principales
plt.figure(figsize=(12, 7))

# Preparar datos
municipios_comparar = ['La Matanza'] + otros_municipios_comparacion['Municipio'].tolist()
valores = [total_matanza] + otros_municipios_comparacion['Cantidad Defunciones'].tolist()

# Crear gr√°fico de barras
bars = plt.bar(municipios_comparar, valores, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])

# A√±adir valores encima de las barras
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
             f'{height:,}\n({round(height/total_provincia*100,1)}%)',
             ha='center', va='bottom', fontsize=10)

plt.title('Comparaci√≥n: La Matanza vs Otros Municipios Principales\n(2017-2022)', fontsize=16)
plt.ylabel('Cantidad de Defunciones', fontsize=12)
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Gr√°fico 3: Heatmap de correlaci√≥n entre municipios
plt.figure(figsize=(12, 10))
corr_matrix = pivot_anual.corr()
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Ocultar duplicados

sns.heatmap(corr_matrix,
            mask=mask,
            annot=True,
            cmap='coolwarm',
            vmin=-1,
            vmax=1,
            center=0,
            fmt='.2f',
            linewidths=0.5,
            cbar_kws={'shrink': 0.8})

plt.title('Correlaci√≥n entre Municipios en Defunciones Fetales\n(2017-2022)', fontsize=16, pad=20)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

# 5. EXPORTACI√ìN A GOOGLE DRIVE
# -----------------------------

# Montar Google Drive (solo en Colab)
drive.mount('/content/drive')

# Definir ruta de guardado
file_path = '/content/drive/MyDrive/MD-TP General/analisis_defunciones_fetales.xlsx'

# Guardar resultados en Excel
with pd.ExcelWriter(file_path) as writer:
    top_10.to_excel(writer, sheet_name='Top 10 Municipios', index=False)
    pivot_anual.to_excel(writer, sheet_name='Evoluci√≥n Anual')
    corr_matrix.to_excel(writer, sheet_name='Correlaciones')
    otros_municipios_comparacion.to_excel(writer, sheet_name='Comparaci√≥n La Matanza', index=False)

    # A√±adir hoja con resumen de otros municipios
    otros_resumen = pd.DataFrame({
        'Categor√≠a': [f'Otros {cant_otros} municipios'],
        'Total Defunciones': [total_otros],
        'Porcentaje': [porcentaje_otros],
        'M√≠nimo': [min_otros],
        'M√°ximo': [max_otros]
    })
    otros_resumen.to_excel(writer, sheet_name='Resumen Otros', index=False)

print("\n" + "="*90)
print(f"AN√ÅLISIS COMPLETADO - RESULTADOS EXPORTADOS A: {file_path}")
print("="*90)

"""# Gr√°ficos Exploratorios

1. Gr√°fico - Evoluci√≥n Total de Defunciones por A√±o:
"""

# Configuraci√≥n inicial
plt.style.use('ggplot')
plt.rcParams['figure.figsize'] = (10, 5)
sns.set_palette("husl")

# Gr√°fico 1: Evoluci√≥n total
defunciones_por_anio = df.groupby('A√±o')['Cantidad Defunciones'].sum().reset_index()

# Convert 'A√±o' column to string before plotting
defunciones_por_anio['A√±o'] = defunciones_por_anio['A√±o'].astype(str)

plt.figure(figsize=(10, 5))
sns.lineplot(data=defunciones_por_anio, x='A√±o', y='Cantidad Defunciones',
             marker='o', linewidth=2.5)
plt.title('Total de Defunciones Fetales por A√±o (2017-2022)', fontsize=14)
plt.xlabel('A√±o', fontsize=12)
plt.ylabel('Total de Defunciones', fontsize=12)
plt.grid(True)
plt.tight_layout()
plt.show()

"""Este gr√°fico de l√≠nea muestra la tendencia temporal del total de defunciones fetales registradas en la Provincia de Buenos Aires entre 2017 y 2022. A lo largo de estos seis a√±os, las cifras presentan una considerable variaci√≥n con un descenso sostenido entre 2017 a 2020.

Registr√°ndose 2051 eventos de defunciones fetales en el a√±o 2017 el valor m√°s alto del periodo, 1696 eventos en 2018; luego se produce una ca√≠da m√°s pronunciada entre 2019-2020, registrando 1406 en 2019 y 1027 en 2020 traduci√©ndose en una reducci√≥n del 14% respecto al a√±o anterior; lo cual puede tener una posible relaci√≥n con las medidas sanitarias durante la pandemia de COVID, donde probablemente hubo un menor registro por la saturaci√≥n del sistema de salud, cambios en protocolos de notificaci√≥n, un efecto de la restricciones implementadas que ocasionaron una menor movilidad y menos controles prenatales.

Se observa tambi√©n una ligera recuperaci√≥n en el a√±o 2021 con 1222 casos y  1362 en el a√±o 2022 alcanzando el valor m√°s bajo del periodo analizado.

2. Gr√°fico - Evoluci√≥n de los 5 municipios con m√°s casos
"""

# Gr√°fico 3: Evoluci√≥n top 5 municipios
top5 = df.groupby('Municipio')['Cantidad Defunciones'].sum().nlargest(5).index.tolist()
df_top5 = df[df['Municipio'].isin(top5)]

# Convert 'A√±o' index to integers representing the year
df_top5 = df_top5.reset_index()  # Reset index to make 'A√±o' a regular column
df_top5['A√±o'] = df_top5['A√±o'].dt.year  # Extract the year as integers

plt.figure(figsize=(12, 6))
lineplot = sns.lineplot(data=df_top5, x='A√±o', y='Cantidad Defunciones',
                        hue='Municipio', marker='o', linewidth=2.5)
plt.title('Evoluci√≥n Anual en los 5 Municipios con M√°s Defunciones', fontsize=14)
plt.xlabel('A√±o', fontsize=12)
plt.ylabel('N√∫mero de Defunciones', fontsize=12)
plt.legend(title='Municipio', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)

# A√±adir etiquetas de valores
for municipio in top5:
    subset = df_top5[df_top5['Municipio'] == municipio]
    for a√±o, valor in zip(subset['A√±o'], subset['Cantidad Defunciones']):
        plt.text(a√±o, valor + 2, str(valor), ha='center', va='bottom')

plt.tight_layout()
plt.show()

"""El gr√°fico de l√≠neas m√∫ltiples presenta un revelador an√°lisis comparativo de la evoluci√≥n temporal de las defunciones fetales en los cinco municipios bonaerenses con mayor carga de casos durante el per√≠odo 2017-2022. La visualizaci√≥n permite identificar patrones epidemiol√≥gicos clave que merecen especial atenci√≥n desde la perspectiva de salud p√∫blica.

Al examinar la trayectoria de cada municipio, se observa una tendencia general descendente que afecta a todas las jurisdicciones. La Matanza, que consistentemente presenta los valores m√°s altos, experiment√≥ una reducci√≥n notable de  196 casos en 2017 hasta 93 en 2022, una disminuci√≥n cercana al 53%. Sin embargo, este descenso no fue lineal, mostr√≥ fluctuaciones interanuales particularmente marcadas entre 2019 y 2020, per√≠odo que coincide con el inicio de la pandemia por COVID-19.

El caso de los registros clasificados como "Ignorado" merece especial consideraci√≥n. Esta categor√≠a, que probablemente agrupa casos de diversos or√≠genes geogr√°ficos, exhibe una variabilidad extrema, con picos en 2017 (361 casos) y 2022 (237 casos), contrastando con valores m√≠nimos en 2018 (49 casos). Esta irregularidad sugiere importantes inconsistencias en los sistemas de registro que podr√≠an estar enmascarando distribuciones territoriales reales.

Los municipios de Lomas de Zamora y Quilmes presentan trayectorias m√°s estables, aunque con descensos igualmente significativos. Florencio Varela, por su parte, muestra un comportamiento particular, siendo el √∫nico donde el a√±o de m√°xima incidencia no fue 2017, sino 2018, con 91 casos registrados.

El an√°lisis cronol√≥gico revela que 2017 emerge como el a√±o cr√≠tico para la mayor√≠a de las jurisdicciones, mientras que 2020 marca un punto de inflexi√≥n donde las curvas de todos los municipios alcanzan sus m√≠nimos relativos o absolutos. Este fen√≥meno podr√≠a relacionarse tanto con mejoras reales en los indicadores de salud materno-infantil como con posibles alteraciones en los sistemas de notificaci√≥n durante la emergencia sanitaria.

La convergencia progresiva de las curvas en los √∫ltimos a√±os sugiere una posible homogeneizaci√≥n en la distribuci√≥n territorial de este problema de salud, aunque esta interpretaci√≥n debe tomarse con cautela debido a la presencia de los casos no georreferenciados. La distancia entre el municipio de La Matanza y Florencio Varela se redujo significativamente, pasando de una diferencia de 296 casos en 2017 a solo 184 casos en 2022.

Esta visualizaci√≥n no solo identifica las √°reas geogr√°ficas que requieren intervenciones prioritarias, sino que tambi√©n plantea interrogantes fundamentales sobre la calidad de los sistemas de registro y la necesidad de implementar mecanismos m√°s robustos de recolecci√≥n de datos. Los patrones observados sirven como punto de partida para investigaciones m√°s profundas que consideren variables socioecon√≥micas, acceso a servicios de salud y pol√≠ticas p√∫blicas implementadas en el per√≠odo.

3. Gr√°fico Heatmap - Correlaci√≥n entre A√±os
"""

# Gr√°fico Correlaci√≥n entre a√±os
pivot_df = df.reset_index().pivot(index='Municipio', columns='A√±o', values='Cantidad Defunciones') # Reset index before pivoting
pivot_df = pivot_df.dropna()
corr_matrix = pivot_df.corr()

plt.figure(figsize=(8, 6))
heatmap = sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=0.5, vmax=1,
                      annot_kws={'size': 12}, fmt='.2f')
plt.title('Correlaci√≥n entre A√±os en Defunciones por Municipio\n(Valores cercanos a 1 indican patrones similares)', fontsize=14)
plt.tight_layout()
plt.show()

"""El Gr√°fico de calor (Heatmap) mide la correlaci√≥n, es decir eval√∫a qu√© tan similares son los patrones de defunciones fetales por municipio durante el periodo de a√±os 2017 - 2022, bas√°ndose en el comportamiento de los municipios. Cada celda representa el coeficiente de correlaci√≥n (rango: 0 a 1), donde los valores cercanos a 1 (tonos rojos) representan patrones casi id√©nticos entre a√±os; mientras que los valores cercanos a 0.5 (tonos azules) representan una correlaci√≥n moderada o inconsistente.

En este an√°lisis, destaca la fuerte correlaci√≥n entre los a√±os 2020 - 2022, con un coeficiente r  >  0.95. Estos valores se√±alan que se mantuvo en este periodo una distribuci√≥n similar de defunciones por municipio, con mayor n√∫mero de defunciones en 2020 repitieron ese mismo patr√≥n en 2022, evidenciando una consistencia notable en su comportamiento y sugiriendo factores estructurales persistentes por ejemplo, el acceso a la salud, condiciones socioecon√≥micas. Por otro lado, la relaci√≥n entre 2020 y 2021 muestra un coeficiente de 0.70, lo cual indica una correlaci√≥n moderada pero no tan s√≥lida como la anterior. Este resultado sugiere que, aunque existe cierta continuidad, hubo factores en 2021 que alteraron parcialmente la tendencia observada el a√±o anterior.

Se observa una baja correlaci√≥n 2017-2019 (r ‚âà 0.7), particularmente los a√±os previos a la pandemia, que muestran patrones menos consistentes, posiblemente por cambios en protocolos de registro o variabilidad en pol√≠ticas locales de salud materno-infantil. En 2019 se evidencia un a√±o de transici√≥n que correla mejor con 2020-2022 (r > 0.8) que con 2017-2018, marcando un punto de inflexi√≥n hacia patrones m√°s estables.

Podemos inferir que la consistencia post-2020 refuerza una hip√≥tesis de que la pandemia homogeneiz√≥ los determinantes de mortalidad fetal, mientras que las diferencias previas (2017-2019) podr√≠an deberse a intervenciones no estandarizadas o mejoras graduales en los sistemas de salud.

4. Gr√°fico Heatmap - Correlaci√≥n entre Municipio - A√±o
"""

# 1. Preparaci√≥n de datos (versi√≥n segura)
try:
    # Crear tabla pivote
    heatmap_data = df.reset_index().pivot_table(
        index='Municipio',
        columns='A√±o',
        values='Cantidad Defunciones',
        aggfunc='sum',
        fill_value=0
    )

    # Ordenar por municipios con m√°s defunciones totales
    heatmap_data = heatmap_data.loc[heatmap_data.sum(axis=1).sort_values(ascending=False).index]

    # Limitar a los 10 municipios principales para mejor visualizaci√≥n
    heatmap_data = heatmap_data.head(10)

    # 2. Configuraci√≥n del heatmap
    plt.figure(figsize=(14, 10))

    sns.heatmap(
        heatmap_data,
        annot=True,
        fmt='d',  # Mostrar n√∫meros enteros
        cmap='YlOrRd',  # Escala amarillo-naranja-rojo
        linewidths=0.5,
        cbar_kws={'label': 'N√∫mero de Defunciones'},
        annot_kws={'size': 9}
    )

    # 3. Personalizaci√≥n
    plt.title('Defunciones Fetales por Municipio y A√±o\n(Top 10 Municipios)',
              fontsize=16, pad=20)
    plt.xlabel('A√±o', fontsize=12)
    plt.ylabel('Municipio', fontsize=12)
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

except Exception as e:
    print(f"Error al generar el heatmap: {str(e)}")
    print("\nPosibles soluciones:")
    print("- Verifica que 'Municipio' y 'A√±o' existen como columnas")
    print("- Aseg√∫rate que 'Cantidad Defunciones' contiene solo n√∫meros")
    print("- Comprueba que no hay valores nulos con: df.isnull().sum()")

"""El mapa de calor muestra la distribuci√≥n de defunciones fetales en los 10 municipios con mayor incidencia durante el per√≠odo 2017-2022. El dato m√°s destacado es la categor√≠a "Ignorado", que registra n√∫meros alarmantes (361 casos en el primer a√±o analizado); el no tener especificado qu√© municipios integran esta categor√≠a indica serios problemas en la recolecci√≥n o clasificaci√≥n de la informaci√≥n; m√°s cuando sus valores en defunciones fetales muestran una variabilidad interanual.

Entre los municipios identificables, la matanza lidera con 196 defunciones iniciales y es el municipio que presenta constantemente valores m√°s alto respecto a los dem√°s municipios; seguido por Lomas de Zamora y Quilmes.
La mayor√≠a de las localidades muestran una disminuci√≥n progresiva de casos siendo 2017 el a√±o con mayor incidencia y 2022 el de menor registro (ejemplo: La Matanza redujo de 196 a 93 casos). No obstante, hay excepciones como ser Florencio Varela tuvo un pico inesperado (de 65 a 91) y Pilar present√≥ un aumento temporal (de 47 a 58).

La escala crom√°tica (amarillo a rojo) permite identificar r√°pidamente los puntos cr√≠ticos, destacando la persistente concentraci√≥n geogr√°fica de estos eventos en el conurbano bonaerense.

# Reporte
"""

!pip install ydata-profiling
from pandas_profiling import ProfileReport
report = ProfileReport(df)
report.to_notebook_iframe()

"""Guardar el Reporte:"""

report.to_file("/content/drive/MyDrive/MD-TP General/Reporte_defunciones_fetales.html")

"""# Mapeo"""

import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
from matplotlib.colors import Normalize
from matplotlib.cm import ScalarMappable

# Suponiendo que tu DataFrame df ya est√° cargado
# Si no, puedes cargarlo as√≠:
# df = pd.read_csv('tu_archivo.csv')  # Ajusta seg√∫n tu fuente de datos

# Paso 1: Obtener los datos geoespaciales de Buenos Aires
# Puedes usar estos archivos geoespaciales comunes:
# Opci√≥n 1: Desde una URL (ejemplo)
# url = "https://raw.githubusercontent.com/geoinquietosarg/GeoJSON-Argentina/master/geojson/provincias/buenos_aires_municipios.geojson"
# gdf = gpd.read_file(url)

# Opci√≥n 2: Si tienes un archivo local en Colab
# Sube el archivo GeoJSON o Shapefile de los municipios de BA a Colab
# from google.colab import files
# uploaded = files.upload()
# gdf = gpd.read_file('tu_archivo_geojson.geojson')

# Como ejemplo, usar√© datos disponibles p√∫blicamente (puede necesitar ajustes)
# Intento con datos de Argentina (puede que necesites instalar geopandas: !pip install geopandas)
try:
    # Intentamos cargar datos de municipios de BA
    gdf = gpd.read_file("https://servicios.usig.buenosaires.gob.ar/geoserver/wfs?srsName=EPSG%3A4326&typename=geonode%3Adivision_politica_municipios&outputFormat=json&version=1.0.0&service=WFS&request=GetFeature")
except:
    # Si falla, usamos datos alternativos (puede requerir ajuste de nombres)
    print("No se pudo cargar datos geoespaciales directamente, usando alternativa...")
    import requests
    url = "https://raw.githubusercontent.com/geoinquietosarg/GeoJSON-Argentina/master/geojson/provincias/buenos_aires_municipios.geojson"
    gdf = gpd.read_file(url)

# Verificamos los datos geoespaciales
print("Columnas en datos geoespaciales:", gdf.columns)
print("Municipios en datos geoespaciales:", gdf['nam'].head() if 'nam' in gdf.columns else gdf['nombre'].head())

# Preparamos los datos de defunciones
# Asegur√©monos de que estamos trabajando con un DataFrame de pandas
df_defunciones = df.reset_index()  # Sacamos 'A√±o' del √≠ndice si es necesario
df_defunciones = df_defunciones[df_defunciones['A√±o'] == 2017]  # Ejemplo para un a√±o

# Paso 2: Unir los datos geoespaciales con los datos de defunciones
# Necesitamos hacer coincidir los nombres de los municipios
# Esto puede requerir ajustes seg√∫n c√≥mo est√©n escritos los nombres

# Primero normalizamos los nombres (eliminamos acentos, may√∫sculas, etc.)
import unicodedata

def normalize_string(text):
    if not isinstance(text, str):
        return ""
    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII')
    return text.lower().strip()

# Aplicamos a ambos DataFrames
gdf['nombre_normalizado'] = gdf['nam'].apply(normalize_string) if 'nam' in gdf.columns else gdf['nombre'].apply(normalize_string)
df_defunciones['Municipio_normalizado'] = df_defunciones['Municipio'].apply(normalize_string)

# Hacemos el merge
merged = gdf.merge(df_defunciones,
                   left_on='nombre_normalizado',
                   right_on='Municipio_normalizado',
                   how='left')

# Verificamos la uni√≥n
print("\nMunicipios coincidentes:", merged[~merged['ID Municipio'].isna()].shape[0])
print("Municipios sin datos:", merged[merged['ID Municipio'].isna()].shape[0])

# Paso 3: Crear el mapa
fig, ax = plt.subplots(1, 1, figsize=(15, 15))

# Configuramos el color seg√∫n la cantidad de defunciones
norm = Normalize(vmin=merged['Cantidad Defunciones'].min(),
                 vmax=merged['Cantidad Defunciones'].max())

# Mapeamos los municipios con datos
merged.plot(column='Cantidad Defunciones',
            cmap='YlOrRd',
            linewidth=0.8,
            ax=ax,
            edgecolor='0.8',
            legend=True,
            norm=norm,
            missing_kwds={'color': 'lightgrey', 'label': 'Sin datos'})

# A√±adimos etiquetas a los municipios (opcional)
for idx, row in merged.iterrows():
    if not pd.isna(row['Cantidad Defunciones']):
        plt.annotate(text=row['Municipio'],
                     xy=row['geometry'].centroid.coords[0],
                     horizontalalignment='center',
                     fontsize=8)

# A√±adimos t√≠tulo y leyenda
ax.set_title('Defunciones por municipio - Provincia de Buenos Aires (2017)', fontsize=16)
ax.set_axis_off()

# A√±adimos barra de color
sm = ScalarMappable(norm=norm, cmap='YlOrRd')
sm.set_array([])
cbar = fig.colorbar(sm, ax=ax, fraction=0.03, pad=0.04)
cbar.set_label('Cantidad de Defunciones', rotation=270, labelpad=20)

plt.tight_layout()
plt.show()

"""# Machine Learning

Importancia de caracter√≠sticas para predecir defunciones fetales
"""

# =============================================
# MODELO DE MACHINE LEARNING PARA PREDICCI√ìN
# =============================================

# Importar librer√≠as adicionales necesarias
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb


# Preparaci√≥n de datos sin modificar el DataFrame original
def preparar_datos_ml(df_original):
    """
    Prepara los datos para ML sin modificar el DataFrame original.
    Devuelve un nuevo DataFrame procesado.
    """
    # Crear copia para no modificar los datos originales
    df_ml = df_original.reset_index().copy()

    # Convertir a√±o a num√©rico
    df_ml['A√±o_num'] = df_ml['A√±o'].dt.year

    # Codificar municipios (evitamos One-Hot para muchos municipios)
    le = LabelEncoder()
    df_ml['Municipio_encoded'] = le.fit_transform(df_ml['Municipio'])

    # Seleccionar caracter√≠sticas y objetivo
    X = df_ml[['A√±o_num', 'Municipio_encoded', 'ID Municipio']]
    y = df_ml['Cantidad Defunciones']

    return X, y, le

# Preparar datos
X, y, label_encoder = preparar_datos_ml(df)

# Dividir en entrenamiento y prueba (80-20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modelo 1: Random Forest
print("\nüîÆ Entrenando modelo Random Forest...")
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Evaluaci√≥n
rf_pred = rf_model.predict(X_test)
print(f"Random Forest - MAE: {mean_absolute_error(y_test, rf_pred):.2f}")
print(f"Random Forest - R¬≤: {r2_score(y_test, rf_pred):.2f}")

# Modelo 2: XGBoost (mejor para datos temporales)
print("\nüîÆ Entrenando modelo XGBoost...")
xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
xgb_model.fit(X_train, y_train)

# Evaluaci√≥n
xgb_pred = xgb_model.predict(X_test)
print(f"XGBoost - MAE: {mean_absolute_error(y_test, xgb_pred):.2f}")
print(f"XGBoost - R¬≤: {r2_score(y_test, xgb_pred):.2f}")

# Funci√≥n para hacer predicciones
def predecir_defunciones(modelo, a√±o, municipio, label_encoder, id_municipio=0):
    """
    Predice defunciones para un municipio y a√±o espec√≠ficos.

    Args:
        modelo: Modelo entrenado (RF o XGB)
        a√±o: A√±o a predecir (ej. 2023)
        municipio: Nombre del municipio (str)
        label_encoder: LabelEncoder usado en entrenamiento
        id_municipio: ID del municipio (opcional)
    """
    try:
        # Codificar municipio
        municipio_encoded = label_encoder.transform([municipio])[0]

        # Crear array de caracter√≠sticas
        X_pred = [[a√±o, municipio_encoded, id_municipio]]

        # Predecir
        prediccion = modelo.predict(X_pred)[0]

        print(f"Predicci√≥n para {municipio} en {a√±o}: {prediccion:.1f} defunciones")
        return prediccion
    except Exception as e:
        print(f"Error en predicci√≥n: {str(e)}")
        return None

# Ejemplo de predicci√≥n
print("\nüìä Ejemplo de predicci√≥n para La Matanza en 2023:")
predecir_defunciones(xgb_model, 2023, "La Matanza", label_encoder)

# Visualizaci√≥n de importancia de caracter√≠sticas
print("\nüìà Importancia de caracter√≠sticas en XGBoost:")
xgb.plot_importance(xgb_model)
plt.title('Importancia de caracter√≠sticas para predecir defunciones fetales')
plt.show()

"""Predicci√≥n por municipio de las posibles cantidad de defunciones fetales en los a√±os 2023 y 2024. El modelo simplificado abarca los tres municipios georreferenciados con mayor cantidad de defunciones fetales en 2017-2022."""

# =============================================
# MODELO SIMPLIFICADO DE PREDICCI√ìN POR MUNICIPIO
# =============================================

# 1. Primero verificamos que los datos est√©n correctamente cargados
print("Verificando estructura de datos...")
print(f"Columnas disponibles: {df.columns.tolist()}")
print(f"A√±os disponibles: {df.index.year.unique()}")

# 2. Funci√≥n simplificada para preparar datos
def preparar_datos_municipio(municipio):
    """Filtra los datos para un municipio espec√≠fico"""
    try:
        datos_municipio = df[df['Municipio'] == municipio].copy()
        if datos_municipio.empty:
            print(f"No hay datos para el municipio: {municipio}")
            return None

        # Asegurarnos de que tenemos todos los a√±os
        a√±os_completos = pd.DataFrame(index=pd.period_range('2017','2022', freq='Y'))
        datos_completos = a√±os_completos.join(datos_municipio['Cantidad Defunciones'])

        # Rellenar valores faltantes con el promedio
        datos_completos = datos_completos.fillna(datos_completos.mean())

        return datos_completos['Cantidad Defunciones']

    except Exception as e:
        print(f"Error preparando datos: {str(e)}")
        return None

# 3. Modelado con Prophet (m√°s robusto para series cortas)
try:
    from prophet import Prophet
    print("Prophet est√° instalado correctamente")
except:
    print("Instalando Prophet...")
    !pip install prophet
    from prophet import Prophet

def predecir_con_prophet(serie, municipio, a√±os_prediccion=1):
    """Predicci√≥n usando Prophet de Facebook"""
    try:
        if serie is None:
            return None

        # Preparar datos para Prophet
        df_prophet = pd.DataFrame({
            'ds': serie.index.to_timestamp(),
            'y': serie.values
        })

        # Modelo simple
        modelo = Prophet(
            yearly_seasonality=False,  # Desactivar estacionalidad anual (pocos datos)
            daily_seasonality=False,
            weekly_seasonality=False
        )
        modelo.fit(df_prophet)

        # Crear dataframe futuro
        futuro = modelo.make_future_dataframe(periods=a√±os_prediccion, freq='Y')
        pronostico = modelo.predict(futuro)

        # Visualizaci√≥n
        fig = modelo.plot(pronostico)
        plt.title(f'Predicci√≥n para {municipio}')
        plt.xlabel('A√±o')
        plt.ylabel('Defunciones Fetales')
        plt.show()

        # Mostrar √∫ltimos valores
        print(f"\nPredicciones para {municipio}:")
        print(pronostico[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(a√±os_prediccion))

        return pronostico

    except Exception as e:
        print(f"Error en Prophet: {str(e)}")
        return None

# 4. Ejecuci√≥n para municipios espec√≠ficos
municipios_ejemplo = ['La Matanza', 'Quilmes', 'Lomas de Zamora']  # Ejemplos

for municipio in municipios_ejemplo:
    print(f"\n{'='*50}")
    print(f"PROCESANDO: {municipio}")
    print("="*50)

    serie = preparar_datos_municipio(municipio)
    if serie is not None:
        prediccion = predecir_con_prophet(serie, municipio, a√±os_prediccion=2)